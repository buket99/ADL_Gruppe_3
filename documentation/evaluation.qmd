# Evaluation

This chapter contains important evaluation results for the modules of the system.

## Image Classifier

This section outlines one good example with saliency maps and one bad example with saliency maps. It also includes a confusion matrix to show the model's performance across all classes.

### Best Case Example
![Best Case Example](images/evaluation/Best_Case.png)

In this example, the model confidently identifies a milk carton. Saliency maps show strong activation around the cow image on the carton, which is a distinctive feature for classifying milk (at least in drinks). However, an interesting observation is the activation around the refrigerator in the background. This may be because many training images for milk cartons likely included refrigerators, leading the model to associate them as a secondary feature.

### Confusion Matrix
![Confusion Matrix](images/evaluation/matrix.png)

The confusion matrix illustrates the model's classification performance across all 11 classes. The diagonal entries represent correctly classified examples, while off-diagonal entries indicate misclassifications. Notably, the model performs exceptionally well for classes like "Coke" and "Water," with very few misclassifications.

### Worst Case Example
![Worst Case Example](images/evaluation/Worst_Case_5.png)

In this example, the model struggles to classify a glass bottle of liquor, a type of data it has not encountered before. The saliency map highlights scattered areas of attention, suggesting uncertainty in where to focus. This highlights a limitation in the model's ability to "generalize" (though there still is no class liquor) to unseen data or domains not represented in the training set.

### Dataset Evolution
As described in the **Domain** > **Data Set** section, the transition from the initial dataset (ds1) to the expanded dataset (ds2) played a crucial role in improving the model's robustness. This evolution was supported by our custom web scraper and additional images captured manually, providing diverse and realistic examples for training.

These evaluations underscore the importance of comprehensive data preparation and illustrate the model's performance under both ideal and challenging scenarios.

## Article Agent

The Article Agent was evaluated based on the word count of 1000 words in the produced article. However, the initial output consistently fell short, averaging 500 to 600 words using GPT-3.5 turbo or GPT-4. Also, various parameters, like the max_tokens or temperature, were changed to reach the word count, but none of the changes made a significant difference.
To solve this, a condition to check if the word count was reached was added. If the total word count of all paragraphs is under 1000 words, an extra paragraph will be added. By adding this, the issue of not reaching enough words was solved.

## Diffusion Model

The Diffusion Model was evaluated for its ability to generate images based on text prompts derived from various aspects of the classified objects, with a focus on quality and generation time. Two different models were tested: `runwayml/stable-diffusion-v1-5` (mid) and `stabilityai/stable-diffusion-2-1-base` (fast).

### Model: `runwayml/stable-diffusion-v1-5` (mid)

This model produced high-quality images that closely matched the descriptive prompts.

#### Example Prompts and Results:

##### Example 1: Composition, Origins, and Production

**Prompt:** "The image depicts a mesmerizing aerial view of a vast expanse of crystal-clear water, symbolizing the essence of life on Earth. In the foreground, gentle ripples can be seen on the surface of the water, reflecting the sunlight and creating a shimmering effect. The water appears deep blue in color, with hints of turquoise near the shorelines, showcasing its purity and tranquility..."

**Image:**
![Generated image for the prompt on water composition](images/example-images/image_1_for_Water_stable-diffusion-v1-5\ \(mid\).png)

##### Example 2: Cultural, Historical, and Practical Importance

**Prompt:** "In the foreground of the image, a serene and sacred river flows gently, reflecting the soft hues of the sky above. The water appears crystal clear, symbolizing purity and life, as it meanders gracefully through a lush landscape..."

**Image:**
![Generated image for the prompt on water's cultural significance](images/example-images/image_2_for_Water_stable-diffusion-v1-5\ \(mid\).png)

##### Example 3: Sensory Experience and Effects

**Prompt:** "In the foreground of the image, a serene lake glistens under the gentle sunlight, creating a mesmerizing play of light and shadow on the water's surface..."

**Generation Time:** The average time to generate an image using this model was around **1 minute and 23 seconds**.

### Model: `stabilityai/stable-diffusion-2-1-base` (fast)

Despite being labeled as "fast," this model took significantly longer to generate images and produced outputs with a noticeable cartoon-like quality, which was less desirable for our application.

#### Example Prompt and Result:

##### Example: Cultural, Historical, and Practical Importance

**Prompt:** "In the foreground of the image, there is a bustling port scene filled with large cargo ships being loaded with crates of milk and dairy products. Workers in uniform are seen carrying and stacking these crates onto the ships, showcasing the active trade of dairy goods on a global scale. The workers are diverse, representing the international nature of the milk trade..."

**Image:**
![Generated image with the 'fast' model](images/example-images/image_2_stable-diffusion-2-1-base\ (fast).png)

**Generation Time:** The average time to generate an image using this model was around **3 hours**. This model was significantly slower compared to the `runwayml/stable-diffusion-v1-5` model.

### Conclusion

The `runwayml/stable-diffusion-v1-5` (mid) model demonstrated superior performance in terms of both image quality and generation time for our specific use case. It successfully captured the essence of the prompts, producing detailed and coherent images. In contrast, the `stabilityai/stable-diffusion-2-1-base` (fast) model, while expected to be faster, exhibited much longer generation times and produced images of lower quality with an undesirable cartoon-like aesthetic.

Both models were tested on an Apple M1 device utilizing the `mps` backend.

## Article Assembler
Below are some examples, that show the general style of the generated articles. The articles are generated based on the prompts from the Article Agent and the images from the Diffusion Model. The text has a length of 1000 words and is structured into four paragraphs. Between the paragraphs, there are images that are generated by the Diffusion Model.
The assembling process takes about 30 seconds to generate the PDF.
![Example Paragraph from an article about water](images/evaluation/page1-example.PNG)

![Example Diffusion Image about water in an article](images/evaluation/page2-example.PNG)

